{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Overview: Analysis of @dog_rates tweets (wrangle_report)\n",
    "Tasked with analysing tweets about the ratings of dogs on the we_rate_dogs archive and get insights like; the most liked type of dogs, average ratings based on the dog types, or the type of dogs that's most tweeted about.\n",
    "\n",
    "The dataset will be wrangled (and analyzing and visualizing) is the tweet archive of Twitter user @dog_rates, also known as WeRateDogs. WeRateDogs is a Twitter account that rates people's dogs with a humorous comment about the dog. These ratings almost always have a denominator of 10. The numerators, though? Almost always greater than 10. 11/10, 12/10, 13/10, etc.\n",
    "\n",
    "The tweet archive of WeRateDogs contains basic tweet data for all 5000+ as it stood on the 1st of August, 2017.\n",
    "\n",
    "### Data Gathering\n",
    "\n",
    "The datasets required for the analysis of the are located in 3 different modes; \n",
    "1. csv dataset already downloaded\n",
    "2. image prediction dataset stored in a url as a .tsv file \n",
    "3. A json.txt dataset holding additional data pulled from tweeter API\n",
    "\n",
    " - The csv file (tweeter-archive-enhanced.csv) was read direcltly into a dataframe using `pd.read_csv('tweeter-archive-enhanced.csv')`\n",
    " - The image_prediction was requested and pulled into dataframe using and \n",
    " - The tweet_json.txt was requested, read, and stored in a separate dataframe.\n",
    " \n",
    "### Assessing\n",
    "#### Visual Assessment\n",
    "The data was visualized manually using microsoft excel to understand the data in a better way. Tidiness issues including poorly structured columns were caught here.\n",
    "\n",
    "#### Programmatic Assessment\n",
    ".info(), .describe(), .sample(), etc. were used to assess the dataset and 8 quality issues were noted .\n",
    " - **Quality Issues**\n",
    "\n",
    "1. Retweeted ratings in tweet archive\n",
    "\n",
    "2. Some names are inappropriate in tweet archive. There are no such names like 'a', 'an', 'o', etc.\n",
    "\n",
    "3. Some Numerators are suspicious and some Denominators are not equal to 10\n",
    "\n",
    "4. Some of the columns in tweet_archive are not essential to analysis\n",
    "\n",
    "5. 66 duplicated images in image_predictions\n",
    "\n",
    "6. Split timestamp in twitter archive into three different columns (day, month, and year)\n",
    "\n",
    "7. tweet_id should be a string rather than an int data type\n",
    "\n",
    "8. retweeted_status_timestamp not needed for analysis\n",
    "\n",
    "### Data Cleaning\n",
    "To clean the datasets, a copy of the datasets were made before attempting to correct the highlighted issues.\n",
    "\n",
    "`tweet_archive_clean = we_rate_dogs.copy()\n",
    "image_pred_clean = img_pred.copy()\n",
    "tweet_json_clean = tweets.copy()`\n",
    "\n",
    "#### Cleaning Quality Issues\n",
    "##### tweet_archive\n",
    " - The retweets and replies in the archived dataset were removed, inappropriate names were replaced with 'None'.\n",
    " - Suspicious numerators were checked and wrong ones were duly corrected while denominators not equal to 10 were corrected.\n",
    " - Columns not essential to the analysis were dropped\n",
    " - The timestamp column was collapsed into the 'day', 'month', and 'year' columns\n",
    " - The retweeted_status_timestamp was also deleted from the dataset\n",
    " \n",
    "##### image_predictions\n",
    " - Duplicated image urls were removed\n",
    " - tweet_id data type was changed from integer to the more appropraite string type\n",
    "\n",
    "##### tweet_json\n",
    " - tweet_id data type was changed from integer to string type\n",
    " \n",
    "#### Cleaning Tidiness Issues\n",
    "\n",
    " - The doggo, floofer, pupper, and puppo columns were pivoted into a single column called 'dog_stage' because it is a structural issue to the analysis. Four columns are holding information that could be held in one\n",
    " - **Finally**, the three datasets were merged into a single master dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
